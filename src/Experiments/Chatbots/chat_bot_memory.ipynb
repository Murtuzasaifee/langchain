{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x107fddfa0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x107725100>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Murtuza, it's nice to meet you!\\n\\nI'm glad to know you're a Solution Architect. That's a very interesting and challenging field. \\n\\nWhat kind of solutions do you typically work on?  What are some of the biggest challenges you face in your role? \\n\\nI'm always eager to learn more about different professions.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 23, 'total_tokens': 103, 'completion_time': 0.145454545, 'prompt_time': 0.000437029, 'queue_time': 0.309470432, 'total_time': 0.145891574}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-47f3cbe2-2aec-4ac4-a886-aadd526b35d6-0', usage_metadata={'input_tokens': 23, 'output_tokens': 80, 'total_tokens': 103})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Murtuza and I am a Solution Architect\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Murtuza, and you are a Solution Architect!  \\n\\nIs there anything else you'd like to know or discuss?  I'm here to help. 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 122, 'total_tokens': 163, 'completion_time': 0.074545455, 'prompt_time': 0.003772265, 'queue_time': 0.289394153, 'total_time': 0.07831772}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-362582c8-3691-4cd4-b6ca-83bbe951cde0-0', usage_metadata={'input_tokens': 122, 'output_tokens': 41, 'total_tokens': 163})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Murtuza and I am a Solution Architect\"),\n",
    "        AIMessage(content=\"Hello Murtuza! It's nice to meet you.\\n\\nBeing a Solution Architect is a fascinating role. What kind of solutions do you typically work on?  \\n\\nDo you have any particular projects or challenges you're working on at the moment that you'd like to discuss? I'm always happy to learn more about what people in different fields are doing.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x10492d080> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(with_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Murtuza,\\n\\nIt's nice to meet you! Being a Solution Architect is a fascinating role. \\n\\nWhat kind of solutions do you typically work on?  \\n\\nI'm eager to learn more about your experience and expertise.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 23, 'total_tokens': 76, 'completion_time': 0.096363636, 'prompt_time': 0.00015387, 'queue_time': 0.267851599, 'total_time': 0.096517506}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c14e53fe-51e3-4c65-a81a-2b34b8e8238d-0', usage_metadata={'input_tokens': 23, 'output_tokens': 53, 'total_tokens': 76})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"msaifee\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Murtuza and I am a Solution Architect\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Murtuza, as you told me at the beginning of our conversation.  😊 \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 88, 'total_tokens': 123, 'completion_time': 0.063636364, 'prompt_time': 0.002528686, 'queue_time': 0.289694045, 'total_time': 0.06616505}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-161e7efd-99b9-4f1d-a8a7-69d6140dbc1d-0', usage_metadata={'input_tokens': 88, 'output_tokens': 35, 'total_tokens': 123})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no access to any personal information about you, including your name. If you'd like to tell me your name, I'd be happy to know!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 13, 'total_tokens': 56, 'completion_time': 0.078181818, 'prompt_time': 8.296e-05, 'queue_time': 0.288522837, 'total_time': 0.078264778}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0504efbe-d1ad-4be9-b588-9eb8deac7590-0', usage_metadata={'input_tokens': 13, 'output_tokens': 43, 'total_tokens': 56})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"jdoe\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a expert in AWS Cloud. Answer all the question to the best of your quality\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Murtuza!\\n\\nI'm glad to be your AWS expert guide.  \\n\\nAsk away! I'll do my best to answer all your questions about AWS in a clear and helpful way.  \\n\\nWhether you're new to the cloud or have some experience, I'm here to help you understand the services, best practices, and possibilities that AWS offers. \\n\\nWhat's on your mind today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 34, 'total_tokens': 127, 'completion_time': 0.169090909, 'prompt_time': 0.000320669, 'queue_time': 0.28833891500000003, 'total_time': 0.169411578}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f612273-e0e5-4fbe-8ec4-e20f0c98ba55-0', usage_metadata={'input_tokens': 34, 'output_tokens': 93, 'total_tokens': 127})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Murtuza\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Murtuza!  \\n\\nIs there something specific you'd like to know about your name, or were you just checking? 😄 \\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 153, 'total_tokens': 190, 'completion_time': 0.067272727, 'prompt_time': 0.005566691, 'queue_time': 0.288056466, 'total_time': 0.072839418}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-666c9bc3-129b-49e4-93e5-a410871a09c7-0', usage_metadata={'input_tokens': 153, 'output_tokens': 37, 'total_tokens': 190})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"msaifee\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Namaste Murtuza! \\n\\nमैं AWS Cloud में एक विशेषज्ञ हूँ और आपकी सभी प्रश्नों के उत्तर देने में आपकी मदद करने के लिए तैयार हूँ। \\n\\nआप मुझसे AWS के बारे में कोई भी प्रश्न पूछ सकते हैं, जैसे:\\n\\n* **सेवाएँ:** EC2, S3, Lambda, RDS, etc. \\n* **डेटाबेस:** MySQL, PostgreSQL, DynamoDB, etc.\\n* **सुरक्षा:** IAM, VPC, Security Groups, etc.\\n* **नेटवर्किंग:** Route 53, CloudFront, etc.\\n* **डिप्लॉयमेंट:** CodeDeploy, CloudFormation, etc.\\n\\nया कोई भी अन्य AWS से संबंधित विषय। \\n\\nमुझे आपके प्रश्नों का इंतजार है!\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 36, 'total_tokens': 214, 'completion_time': 0.323636364, 'prompt_time': 0.00030478, 'queue_time': 0.287148488, 'total_time': 0.323941144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-98f0bf33-5c25-4ee6-85bf-e53b82a83239-0', usage_metadata={'input_tokens': 36, 'output_tokens': 178, 'total_tokens': 214})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a expert in AWS Cloud. Answer all the question to the best of your quality in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n",
    "\n",
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Murtuza\")], \"language\":\"Hindi\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/murtuzasaifee/Documents/Personal/Codes/AgenticAIWorkspace/langchain/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trimming the Chat History\n",
    "\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like vanilla ice cream!  🍦 😊 \\n\\n\\n\\nAnything else I can help you with?\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model \n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked: \"whats 2 + 2\" \\n\\nI\\'m ready for another one if you have it! 😊  \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
